{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Image Classification using Convolutional Neural Networks\n",
    "\n",
    "In this project our aim was to classify images using Convolutional Neural Networks, to do so we used the Inception-V3 Network, which is trained for the ImageNet Large Visual Recognition Challenge using the data from 2012. Furthermore this model is able to achieve 76.88% Top-1 Accuracy and 93.344% Top-5 Accuracy on ILSVRC2012-Validation Set.\n",
    "\n",
    "To do so, we used R and MXNet, generating an interactive user interface with Shiny where the user can upload images in oder to classify them. Hence, first of all we had to load all the required packages (libraries):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: shiny\n",
      "Loading required package: mxnet\n",
      "Loading required package: imager\n",
      "Loading required package: plyr\n",
      "Loading required package: magrittr\n",
      "\n",
      "Attaching package: ‘imager’\n",
      "\n",
      "The following object is masked from ‘package:magrittr’:\n",
      "\n",
      "    add\n",
      "\n",
      "The following object is masked from ‘package:plyr’:\n",
      "\n",
      "    liply\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    convolve, spectrum\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    frame\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    save.image\n",
      "\n",
      "Loading required package: scales\n",
      "Loading required package: jpeg\n",
      "Loading required package: ggplot2\n",
      "Loading required package: readr\n",
      "\n",
      "Attaching package: ‘readr’\n",
      "\n",
      "The following object is masked from ‘package:scales’:\n",
      "\n",
      "    col_factor\n",
      "\n",
      "Loading required package: png\n",
      "Loading required package: ggthemes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>shiny</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>mxnet</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>imager</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>scales</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>jpeg</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>ggplot2</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>readr</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>png</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>ggthemes</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[shiny] TRUE\n",
       "\\item[mxnet] TRUE\n",
       "\\item[imager] TRUE\n",
       "\\item[scales] TRUE\n",
       "\\item[jpeg] TRUE\n",
       "\\item[ggplot2] TRUE\n",
       "\\item[readr] TRUE\n",
       "\\item[png] TRUE\n",
       "\\item[ggthemes] TRUE\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "shiny\n",
       ":   TRUEmxnet\n",
       ":   TRUEimager\n",
       ":   TRUEscales\n",
       ":   TRUEjpeg\n",
       ":   TRUEggplot2\n",
       ":   TRUEreadr\n",
       ":   TRUEpng\n",
       ":   TRUEggthemes\n",
       ":   TRUE\n",
       "\n"
      ],
      "text/plain": [
       "   shiny    mxnet   imager   scales     jpeg  ggplot2    readr      png \n",
       "    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE \n",
       "ggthemes \n",
       "    TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "required_packages <- c(\"shiny\", \"mxnet\", \"imager\", \"scales\", \"jpeg\", \"ggplot2\", \"readr\", \"png\", \"ggthemes\")\n",
    "sapply(required_packages, require, character.only = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Inception-V3 Network has some constraints regarding the image input dimensions which need to be single crop on 299 x 299 image, to do so we defined a preprocessing function, which preprocesses the images before inputting them in the Network model, below we can find the code for the preprocessing (an adaptation of the code provided in the inception v3 model but translated to R):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc.image <- function(image) {\n",
    "  \n",
    "\n",
    "  shape <- dim(image)\n",
    "  short.edge <- min(shape[1:2])\n",
    "  xx <- floor((shape[1] - short.edge) / 2)\n",
    "  yy <- floor((shape[2] - short.edge) / 2) \n",
    "  croped <- crop.borders(image, xx, yy)\n",
    "  resized <- resize(croped, 299, 299)\n",
    "  array <- as.array(resized) * 256\n",
    "  dim(array) <- c(299, 299, 3)\n",
    "  preprocessedImage <- array - 128\n",
    "  preprocessedImage <- array/128\n",
    "  \n",
    "  dim(preprocessedImage) <- c(299, 299, 3, 1)\n",
    "  return(preprocessedImage)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we defined the preprocessing function, we can proceed to download the model and define the model and the classes used in this model. To do so, we will check if the file \"model\", which is the name of the folder where Inception V3 model is contained is found in the computer. If it is not found, we will proceed to download and untar the model, and then we will load the model to our system and also the classes (which are in txt format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (!file.exists(\"model\")) {\n",
    "    download.file(\"http://data.dmlc.ml/mxnet/models/imagenet/inception-v3.tar.gz\", destfile = \"inception-v3.tar.gz\")\n",
    "    untar(\"inception-v3.tar.gz\")\n",
    "  }\n",
    "  \n",
    "  ImageNet_Model <- mx.model.load(\"model/Inception-7\", iteration = 1)\n",
    "  \n",
    "  synsets <- read_lines(\"model/synset.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the preprocessing function we also defined a function to pick an image from some location (in the web or in the local computer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picksource <- function(input){\n",
    "  \n",
    "  ImageFromUrl <- eventReactive(input$enter, {\n",
    "    print(input$urlImage)\n",
    "   \n",
    "      image <- tempfile()\n",
    "      download.file(input$urlImage, destfile = image, method = \"auto\")\n",
    "      return(image)\n",
    "    \n",
    "  })\n",
    "  \n",
    "  \n",
    "  src = if (input$tabs == \"Upload Image\") {\n",
    "    if (is.null(input$Imagefile)) {\n",
    "      if (input$goButton == 0 || is.null(ImageFromUrl())) {\n",
    "        'image.jpg'\n",
    "      } else {\n",
    "        ImageFromUrl()\n",
    "      }\n",
    "    } else {\n",
    "      input$Imagefile$datapath\n",
    "    }\n",
    "  } else {\n",
    "    if (input$goButton == 0 || is.null(ImageFromUrl())) {\n",
    "      if (is.null(input$Imagefile)) {\n",
    "        'image.jpg'\n",
    "      } else {\n",
    "        input$Imagefile$datapath\n",
    "      }\n",
    "    } else {\n",
    "      ImageFromUrl()\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we will define a function to appropiately format the results, formatting the final results in a nice and visual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCommonResults <- function(result){\n",
    "  StringResult <- \"\"\n",
    "  for (i in 1:5) {\n",
    "    ResultInJ <- strsplit(result[i], \" \")[[1]]\n",
    "    for (j in 2:length(ResultInJ)) {\n",
    "      StringResult <- paste(StringResult, ResultInJ[j])\n",
    "    }\n",
    "    StringResult <- paste(StringResult, \"\\n\")\n",
    "  }\n",
    "  StringResult\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined all the previous functions, we will define our shiny user interface, in this user inferface we defined a side by side layout, where we defined in one side a panel to upload an image from the computer or from an url. And in the other side we defined a panel where the results will be displayed, displaying the inputted image, the predicted classes and its probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define UI for application that draws a histogram\n",
    "ui <- fluidPage(\n",
    "  \n",
    "  includeCSS('alike.css'),\n",
    "  # Application title\n",
    "  titlePanel(\"Image Classification using Convolutional Neural Networks\"),\n",
    "  \n",
    "  # Sidebar with a slider input for number of bins \n",
    "  sidebarLayout(\n",
    "    sidebarPanel(\n",
    "      tabsetPanel(\n",
    "        id = \"tabs\",\n",
    "        tabPanel(\"Upload Image\",\n",
    "                 fileInput('Imagefile', '\\n Upload an Image:')),\n",
    "        tabPanel(\n",
    "          \"Use the URL\",\n",
    "          textInput(\"urlImage\", \"Enter an Image URL:\", \"\"),\n",
    "          actionButton(\"enter\", \"OK\")\n",
    "        )\n",
    "      )\n",
    "    ),\n",
    "    \n",
    "    # Show the image, the results and the probabilities\n",
    "    mainPanel(\n",
    "      h3(\"Image to classify\"),\n",
    "      tags$hr(),\n",
    "      imageOutput(\"imageloaded\", height = \"auto\"),\n",
    "      tags$hr(),\n",
    "      h3(\"What does the image contains?\"),\n",
    "      tags$hr(),\n",
    "      verbatimTextOutput(\"res\"),\n",
    "      plotOutput(\"ProbPlot\")\n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we had to define the actions behind the user interface, i.e. define what each interface does. To do so we generated a server, where we defined the logic required to pick an image submitted by the user and predict its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "server <- function(input, output) {\n",
    "  \n",
    "  image <- NULL\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  output$imageloaded = renderImage(list(src = picksource(input)), deleteFile = FALSE)\n",
    "  \n",
    "  \n",
    "  \n",
    "  output$res <- renderText({\n",
    "    src <- picksource(input)\n",
    "    \n",
    "    im <- load.image(src)\n",
    "    preprocessedImage <- preproc.image(im)\n",
    "    prob <- predict(ImageNet_Model, X = preprocessedImage)\n",
    "    max.idx <- order(prob[,1], decreasing = TRUE)[1:5]\n",
    "    result <- synsets[max.idx]\n",
    "    StringResult <- \"\"\n",
    "    for (i in 1:5) {\n",
    "      ResultInJ <- strsplit(result[i], \" \")[[1]]\n",
    "      for (j in 2:length(ResultInJ)) {\n",
    "        StringResult <- paste(StringResult, ResultInJ[j])\n",
    "      }\n",
    "      StringResult <- paste(StringResult, \"\\n\")\n",
    "    }\n",
    "    StringResult\n",
    "  })\n",
    "  \n",
    "  \n",
    "  \n",
    "  output$res <- renderText({\n",
    "    src <- picksource(input)\n",
    "    \n",
    "    im <- load.image(src)\n",
    "    preprocessedImage <- preproc.image(im)\n",
    "    prob <- predict(ImageNet_Model, X = preprocessedImage)\n",
    "    max.idx <- order(prob[,1], decreasing = TRUE)[1:5]\n",
    "    result <- synsets[max.idx]\n",
    "    StringResult <- StringResult <- getCommonResults(result)\n",
    "  })\n",
    "  \n",
    "  output$ProbPlot <- renderPlot({\n",
    "   src <- picksource(input)\n",
    "    \n",
    "    im <- load.image(src)\n",
    "    preprocessedImage <- preproc.image(im)\n",
    "    prob <- predict(ImageNet_Model, X = preprocessedImage)\n",
    "    max.idx <- order(prob[,1], decreasing = TRUE)[1:5]\n",
    "    result <- synsets[max.idx]\n",
    "    StringResult <- getCommonResults(result)\n",
    "    \n",
    "    \n",
    "    StringResult1 <- unlist(strsplit(StringResult, split=\"\\n\"))\n",
    "    StringResult1 <- data.frame(names = StringResult1, probability = sort(prob[,1], decreasing = TRUE)[1:5])\n",
    "    ggplot(StringResult1) + geom_bar(aes(reorder(names, probability ), probability * 100), stat = \"identity\", fill = \"cyan\", alpha = 1/3) + coord_flip() +\n",
    "      labs(x = \"Names\", y = \"Probability (%)\") + theme_solarized_2(light = FALSE) + theme_hc(bgcolor = \"darkunica\") +\n",
    "      scale_colour_hc(\"darkunica\")\n",
    "  })\n",
    "  \n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the user and server, we can run the application by running the following chunck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Listening on http://127.0.0.1:5759\n"
     ]
    }
   ],
   "source": [
    "shinyApp(ui = ui, server = server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Note: In order to access to the application click on the url generated after running the previous chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Szegedy, Christian, et al. \"Rethinking the Inception Architecture for Computer Vision.\" arXiv preprint arXiv:1512.00567 (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
